{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZXB7WM81ygu"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhWt6DDX1yB8",
    "outputId": "7053acb5-17e2-45c8-fc22-8074d9018976",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "#NLTK\n",
    "import nltk \n",
    "\n",
    "#Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Embedding, LSTM\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#SKLEARN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-hCGQqW2o2D"
   },
   "source": [
    "# Files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoY1m43i24nU"
   },
   "source": [
    "## Dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0bHQUy31HL_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"C:/Users/Ibrah/OneDrive/Bureau/Projects/Twitter Sentiment Analysis/Dataset/training_dataset.csv\", encoding=\"latin\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9_eOnd67Qpr"
   },
   "source": [
    "# Show some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tPuZ_Aht7QC5",
    "outputId": "b79de459-6d91-411b-feb3-1cb39e67a14a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-z4s8BS3ffz"
   },
   "source": [
    "# Setting headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzL75RoC2zrt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_names = [\"target\",\"id\",\"date\",\"query\",\"username\",\"content\"]\n",
    "dataset.columns = column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xOOdN0W8BNd"
   },
   "source": [
    "## Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIDAVUeM3dH-",
    "outputId": "74f9c012-e9a9-4b10-cf86-b1413eb7d258",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6f8D7BM9pXq"
   },
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YaoqG3b9C0Y"
   },
   "source": [
    "## Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhED0yWp7ihG",
    "outputId": "69eba5ef-81e0-41ca-9af0-3c2b55c4d0eb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "missing_values = dataset.isna().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JO4eJJq-9xcr"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    " There are 0 missing values within this dataset\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSq9QERv-jvp"
   },
   "source": [
    "## Target distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8tlUnkH-nZQ"
   },
   "source": [
    "### Negative samples : *target = 0*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsdSJiGIANXH"
   },
   "source": [
    "#### Display some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uv8bxTGD9V3l",
    "outputId": "0c83028f-78f0-4bd5-d8eb-c44dd6a1dc47",
    "tags": []
   },
   "outputs": [],
   "source": [
    "negative_samples = dataset[dataset[\"target\"]==0]\n",
    "negative_samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prqugzCzAQ6P"
   },
   "source": [
    "#### Show count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6Zba76H-17c",
    "outputId": "19449631-06a7-43c3-fff3-f2d407e4c4d1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "negative_samples_count = len(negative_samples)\n",
    "print(f\"Number of negative samples : {negative_samples_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KM1ZuqFEA6x3"
   },
   "source": [
    "### Neutral samples : *target=2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97HrhrQJBOo7"
   },
   "source": [
    "#### Display some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DT7jZMCAecG",
    "outputId": "3ada8019-9f04-4135-c142-f622fe23164e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "neutral_samples = dataset[dataset[\"target\"]==2]\n",
    "neutral_samples.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZc0FQiKCBK5"
   },
   "source": [
    "#### Show count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdBUfV1IBYGa",
    "outputId": "0f6a8ba5-d0a2-4955-b387-6cfcfe872cbd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "neutral_samples_count = len(neutral_samples)\n",
    "print(f\"Number of neutral samples : {neutral_samples_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHOQYpNmCL6-"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "0 neutral sample ? Wow\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqkK7OZXCROU"
   },
   "source": [
    "### Positive samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dcvq0b1VCYOX"
   },
   "source": [
    "#### Display some results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sre7a5oBCQ1Q",
    "outputId": "3b46ce62-a57a-400a-900c-5edfe72418b7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "positive_samples = dataset[dataset[\"target\"]==4]\n",
    "positive_samples.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IQcfsgYC1iy"
   },
   "source": [
    "#### Show count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LumGz_fvCJj3",
    "outputId": "815f5451-258f-4967-a261-a1e565d14443",
    "tags": []
   },
   "outputs": [],
   "source": [
    "positive_samples_count = len(positive_samples)\n",
    "print(f\"Number of positive samples {positive_samples_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZYiR8QDDfnp"
   },
   "source": [
    "## Target distribution plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Am3AkLNEF9e"
   },
   "source": [
    "#### Defining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5EdHWdBdDej7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = [negative_samples_count, neutral_samples_count, positive_samples_count]\n",
    "labels = [\"Negative\",\"Neutral\",\"Positive\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uj1-OsBnEJrV"
   },
   "source": [
    "#### Define color palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pXz_gP0-DdNQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"pastel\")[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESqP10mDEUhf"
   },
   "source": [
    "#### Create pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGGg2baaETLr",
    "outputId": "ed0e2df0-c414-42ce-e69c-6e4320857c1c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Target distribution\")\n",
    "plt.pie(data, labels=labels, colors=colors, autopct=\"%.0f%%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTZEZqv_HZOE"
   },
   "source": [
    "# Preparing data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz1BulVbHdGl"
   },
   "source": [
    "## Drop unncessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WyZ8e3VLEjfL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.drop([\"id\",\"date\",\"query\",\"username\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMcitFGUHzPC"
   },
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFdq0LhqHysm",
    "outputId": "9a7a159c-7c79-4bef-b162-f07fd3df19d4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace 4 by 1 (TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.target = dataset.target.replace({4: 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset[dataset[\"target\"]==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBAfnoUyISya"
   },
   "source": [
    "## Removing mentions, links, extra spaces from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikqW_T2zH13p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "regex = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9jaNykeM_yj"
   },
   "source": [
    "### Apply preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EoABeZwEM-r1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.content = dataset.content.apply(lambda x: re.sub(regex, ' ', str(x).lower()).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqB9ujzoNZ16"
   },
   "source": [
    "### Show results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IwBkikKNG-6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4v0DrR2mOwG-"
   },
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoKZ8VeBOWzJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.1, random_state=44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40W8tb84Pb7c"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "The dataset is large enough to proceed to a 90-10 split. \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mReEzwzPr9x"
   },
   "source": [
    "### Display results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aECLgCaePjaU",
    "outputId": "7627359b-9e41-4fa5-8ffc-daaba24acbd4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Training set length: {len(train)/1e6}M examples\")\n",
    "print(f\"Test set length: {len(test)/1e6}M examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lG9lPGZgQJ7r"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XG5wc4ugQ18w"
   },
   "source": [
    "### Define the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGx6CvE8P2Tv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train.content)\n",
    "vocab_size = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Word index length: {len(tokenizer.word_index)}\")\n",
    "print(f\"Some words: {list(tokenizer.word_index.keys())[0:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pbm6bM-7RIuW"
   },
   "source": [
    "### Get the max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIRR_133RC2W",
    "tags": []
   },
   "outputs": [],
   "source": [
    "content = dataset[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wb1Y8hnVRR-U",
    "outputId": "48614b23-8caf-403c-ce10-d49cb521ce94",
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = len(content[0].split())\n",
    "for tweet in content: \n",
    "  length = len(tweet.split())\n",
    "  if length > max_length: \n",
    "    max_length = length\n",
    "\n",
    "print(f\"Maximum token length: {max_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoV-mJttTZvW"
   },
   "source": [
    "### Define sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BH5ehzZzRdB0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequences_train = tokenizer.texts_to_sequences(train.content)\n",
    "sequences_test = tokenizer.texts_to_sequences(test.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qBX1xc-TpbU"
   },
   "source": [
    "### Define X_train, X_test, y_train, y_test, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UoiSTXzfTnLl",
    "outputId": "cab2975a-b088-4309-f884-88b39eb5a926",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pad_sequences(sequences_train, maxlen=max_length, padding='post')\n",
    "X_test = pad_sequences(sequences_test, maxlen=max_length, padding='post')\n",
    "\n",
    "y_train = train.target.values\n",
    "y_test = test.target.values\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryPd1T9BVkBa"
   },
   "source": [
    "## Word Embeddings (GloVe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXKpPqNFWK3n"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJqPXut3VWWh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_dictionary = dict()\n",
    "embedding_dim = 100\n",
    "glove_file = open(\"C:/Users/Ibrah/OneDrive/Bureau/Projects/Twitter Sentiment Analysis/Dataset/word_embeddings.txt\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUEMLeF-Wops"
   },
   "source": [
    "### Apply word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISKnOvqPWHwc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "    \n",
    "glove_file.close()\n",
    "\n",
    "embeddings_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embeddings_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1O7nHkcX98b"
   },
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzmRd54PYA1R"
   },
   "source": [
    "## Set training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPEKs1DiWRQq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lONAiPiYb4K"
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-MBH9dkYgGH"
   },
   "source": [
    "### Define the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v55TleKdYEvX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_size, embedding_dim, input_length=max_length, weights=[embeddings_matrix], trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFD3_-1WeZ0k"
   },
   "source": [
    "### Define early stopping as the model callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1aTkm9geZKZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=10, mode =\"max\", verbose=2, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xh5SCzMYnI6"
   },
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zlQFKnznacrY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        embedding_layer,\n",
    "        tf.keras.layers.Bidirectional(LSTM(128, return_sequences=True)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Bidirectional(LSTM(128, return_sequences=True)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Bidirectional(LSTM(128)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBLDT_nyZuD3"
   },
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cs-ego69YrAj"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "       optimizer = Adam(learning_rate = 0.001 ),\n",
    "       loss=\"binary_crossentropy\", \n",
    "       metrics=[\"accuracy\"]\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QFsvRwkbent"
   },
   "source": [
    "## Model summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQXLnEwgZzy6",
    "outputId": "98606ea4-b661-474d-b409-e4ae837b4fd4"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nsbS_JxcfnkB",
    "outputId": "2dc9dfda-f615-41bb-c01a-60aa665eb9bb"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1wMN2Lcbq3V"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ExFPK4f3bhay",
    "outputId": "cdc7f500-6ba1-45a7-d1cd-3ae4a8540444"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1, \n",
    "    validation_data=(X_test,y_test),\n",
    "    callbacks = [stop_early]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Define text vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(tokenizer.word_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = tf.keras.Input(shape=(max_length))\n",
    "shape = input_shape.shape\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = TextVectorization(\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    max_tokens=vocab_size+1,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_length, \n",
    "    vocabulary=vocabulary\n",
    ")\n",
    "vectorize_layer.adapt(train[\"content\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(1,), dtype=tf.string),\n",
    "    vectorize_layer,\n",
    "    model,\n",
    "    Activation('sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model.compile(\n",
    "       optimizer = Adam(learning_rate = 0.001 ),\n",
    "       loss=\"binary_crossentropy\", \n",
    "       metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model.save(\"TSA_model_v3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = len(history.history[\"loss\"])\n",
    "print(f\"Number of epochs: {number_of_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(number_of_epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = max(history.history[\"val_accuracy\"])\n",
    "print(f\"Best validation accuracy : {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print f1-score, precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions = np.where(predictions<0.5, 0, 1)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\"being sick can be really cheap when it hurts too much to eat real food plus your friends make you soup\"]\n",
    "\n",
    "print(\"Examples: \", examples, \" Type: \", type(examples))\n",
    "\n",
    "export_model.predict(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune the threshold (experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the best f1 score for each threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 1, 0.001)\n",
    "thres = 0.1\n",
    "f1_score = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in thresholds :\n",
    "    prediction = np.where(predictions>threshold, 1, 0)\n",
    "    report = classification_report(y_test, prediction, output_dict=True)\n",
    "    f1_score_new = report[\"1\"][\"f1-score\"]\n",
    "    if f1_score_new > f1_score: \n",
    "        f1_score = f1_score_new\n",
    "        thres = threshold\n",
    "                      \n",
    "print(f\"Best threshold : {thres} \\nBest f1_score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres_neg = 0.1\n",
    "f1_score_neg = 0.001\n",
    "for threshold in thresholds :\n",
    "    prediction = np.where(predictions>threshold, 1, 0)\n",
    "    report = classification_report(y_test, prediction, output_dict=True)\n",
    "    f1_score_new = report[\"0\"][\"f1-score\"]\n",
    "    if f1_score_new > f1_score_neg: \n",
    "        f1_score_neg = f1_score_new\n",
    "        thres_neg = threshold\n",
    "                      \n",
    "print(f\"Best threshold : {thres_neg} \\nBest f1_score: {f1_score_neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [ \"this is a very good day, don't you think so ?\" ]\n",
    "\n",
    "print(\"Examples: \", examples, \" Type: \", type(examples))\n",
    "\n",
    "export_model.predict(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
